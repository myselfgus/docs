name: ü§ñ Auto Documentation Update

on:
  push:
    branches: [ main, develop ]
    paths:
      - '**/*.md'
      - '**/*.py'
      - '**/*.js'
      - '**/*.ts'
      - '**/*.json'
      - '**/*.yml'
      - '**/*.yaml'
  pull_request:
    branches: [ main ]
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      update_type:
        description: 'Type of documentation update'
        required: true
        default: 'comprehensive'
        type: choice
        options:
        - comprehensive
        - structure_only
        - metadata_only

env:
  DOCUMENTATION_STANDARDS_VERSION: "2.0"
  AUTO_UPDATE_ENABLED: true

jobs:
  validate-and-update-docs:
    name: üìö Validate and Update Documentation
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write

    steps:
      - name: üîç Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: üì¶ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            echo "Installing dependencies from requirements.txt..."
            pip install -r requirements.txt
          else
            echo "No requirements.txt found, installing fallback dependencies..."
            pip install requests pyyaml python-frontmatter markdownify beautifulsoup4
          fi

      - name: üîç Detect Changes
        id: changes
        run: |
          echo "Detecting documentation changes..."
          
          # Get list of changed files
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }})
          else
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          fi
          
          echo "Changed files:"
          echo "$CHANGED_FILES"
          
          # Check if any documentation-relevant files changed
          HAS_DOCS_CHANGES=false
          HAS_NEW_FILES=false
          HAS_CONTENT_CHANGES=false
          
          for file in $CHANGED_FILES; do
            if [[ "$file" =~ \.(md|py|js|ts|json|yml|yaml)$ ]]; then
              HAS_DOCS_CHANGES=true
              if [[ ! -f "$file" ]] || [[ $(git log --oneline "$file" | wc -l) -eq 1 ]]; then
                HAS_NEW_FILES=true
              fi
              if [[ "$file" =~ \.(md)$ ]]; then
                HAS_CONTENT_CHANGES=true
              fi
            fi
          done
          
          echo "has_docs_changes=$HAS_DOCS_CHANGES" >> $GITHUB_OUTPUT
          echo "has_new_files=$HAS_NEW_FILES" >> $GITHUB_OUTPUT
          echo "has_content_changes=$HAS_CONTENT_CHANGES" >> $GITHUB_OUTPUT
          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: üîß Run Documentation Validation
        if: steps.changes.outputs.has_docs_changes == 'true'
        run: |
          echo "Running documentation validation..."
          make validate || echo "Validation completed with warnings"

      - name: üìä Generate Documentation Statistics
        if: steps.changes.outputs.has_docs_changes == 'true'
        run: |
          echo "Generating documentation statistics..."
          make stats > docs_stats.txt
          cat docs_stats.txt

      - name: ü§ñ Invoke Copilot Agent for Documentation Update
        if: steps.changes.outputs.has_docs_changes == 'true'
        id: copilot_update
        run: |
          echo "Preparing Copilot Agent invocation..."
          
          # Create prompt for Copilot based on changes
          cat > copilot_prompt.md << 'EOF'
          # Documentation Update Request
          
          ## Context
          - Repository: ${{ github.repository }}
          - Branch: ${{ github.ref_name }}
          - Event: ${{ github.event_name }}
          - Changed Files: ${{ steps.changes.outputs.changed_files }}
          
          ## Task
          Please analyze the changed files and update the documentation according to the established rules:
          
          1. **Update VOITHER_Knowledge_Graph_Updated.md** with new information from changed files
          2. **Ensure all new .md files have proper YAML frontmatter** following the established standard
          3. **Update DOCUMENTATION_INDEX.md** with new files and statistics
          4. **Update TABLE_OF_CONTENTS.md** if new sections are needed
          5. **Validate all internal links** and fix any broken ones
          6. **Apply consistent formatting** and navigation aids
          
          ## Established Documentation Rules
          - Every .md file must have YAML frontmatter with: title, description, version, last_updated, audience, priority, reading_time, tags
          - Long documents need "Quick Navigation" sections
          - Use consistent tagging for discoverability
          - Maintain cross-references between related documents
          - Update last_updated dates when content changes
          - Follow the writing standards in CONTRIBUTING.md
          
          ## Changes Detected
          - New files: ${{ steps.changes.outputs.has_new_files }}
          - Content changes: ${{ steps.changes.outputs.has_content_changes }}
          - Update type: ${{ inputs.update_type || 'comprehensive' }}
          
          Please proceed with the documentation updates following these guidelines.
          EOF
          
          echo "Copilot prompt prepared"
          echo "update_needed=true" >> $GITHUB_OUTPUT

      - name: üìù Update Documentation Index
        if: steps.changes.outputs.has_new_files == 'true'
        run: |
          echo "Updating documentation index..."
          python << 'EOF'
          import os
          import yaml
          import frontmatter
          from datetime import datetime
          
          def update_documentation_index():
              docs_data = []
              total_lines = 0
              
              for root, dirs, files in os.walk('.'):
                  # Skip .git and other hidden directories
                  dirs[:] = [d for d in dirs if not d.startswith('.')]
                  
                  for file in files:
                      if file.endswith('.md'):
                          filepath = os.path.join(root, file)
                          
                          try:
                              with open(filepath, 'r', encoding='utf-8') as f:
                                  post = frontmatter.load(f)
                                  lines = len(f.readlines())
                                  total_lines += lines
                                  
                                  doc_info = {
                                      'file': filepath[2:],  # Remove ./
                                      'title': post.metadata.get('title', file[:-3]),
                                      'description': post.metadata.get('description', 'No description'),
                                      'audience': post.metadata.get('audience', []),
                                      'priority': post.metadata.get('priority', 'unspecified'),
                                      'reading_time': post.metadata.get('reading_time', 'Unknown'),
                                      'tags': post.metadata.get('tags', []),
                                      'lines': lines
                                  }
                                  docs_data.append(doc_info)
                          except Exception as e:
                              print(f"Error processing {filepath}: {e}")
              
              # Update DOCUMENTATION_INDEX.md with new statistics
              current_date = datetime.now().strftime('%Y-%m-%d')
              
              with open('DOCUMENTATION_INDEX.md', 'r', encoding='utf-8') as f:
                  content = f.read()
              
              # Update statistics in the file
              import re
              content = re.sub(r'- \*\*Total Documents\*\*: \d+', f'- **Total Documents**: {len(docs_data)}', content)
              content = re.sub(r'- \*\*Total Lines\*\*: [\d,]+', f'- **Total Lines**: {total_lines:,}', content)
              content = re.sub(r'last_updated: "[^"]*"', f'last_updated: "{current_date}"', content)
              
              with open('DOCUMENTATION_INDEX.md', 'w', encoding='utf-8') as f:
                  f.write(content)
              
              print(f"Updated documentation index: {len(docs_data)} files, {total_lines:,} lines")
          
          update_documentation_index()
          EOF

      - name: üè∑Ô∏è Add Missing Frontmatter
        if: steps.changes.outputs.has_content_changes == 'true'
        run: |
          echo "Adding missing frontmatter to .md files..."
          python << 'EOF'
          import os
          import frontmatter
          from datetime import datetime
          
          def add_missing_frontmatter():
              current_date = datetime.now().strftime('%Y-%m-%d')
              
              for root, dirs, files in os.walk('.'):
                  # Skip .git and other hidden directories  
                  dirs[:] = [d for d in dirs if not d.startswith('.')]
                  
                  for file in files:
                      if file.endswith('.md'):
                          filepath = os.path.join(root, file)
                          
                          try:
                              with open(filepath, 'r', encoding='utf-8') as f:
                                  post = frontmatter.load(f)
                              
                              needs_update = False
                              
                              # Add missing frontmatter fields
                              if not post.metadata.get('title'):
                                  post.metadata['title'] = file[:-3].replace('_', ' ').title()
                                  needs_update = True
                              
                              if not post.metadata.get('description'):
                                  post.metadata['description'] = f"Documentation for {post.metadata.get('title', file[:-3])}"
                                  needs_update = True
                              
                              if not post.metadata.get('version'):
                                  post.metadata['version'] = "1.0"
                                  needs_update = True
                              
                              if not post.metadata.get('last_updated'):
                                  post.metadata['last_updated'] = current_date
                                  needs_update = True
                              
                              if not post.metadata.get('audience'):
                                  post.metadata['audience'] = ["general"]
                                  needs_update = True
                              
                              if not post.metadata.get('priority'):
                                  post.metadata['priority'] = "important"
                                  needs_update = True
                              
                              if not post.metadata.get('reading_time'):
                                  # Estimate reading time (250 words per minute)
                                  word_count = len(post.content.split())
                                  reading_time = max(1, round(word_count / 250))
                                  post.metadata['reading_time'] = f"{reading_time} minutes"
                                  needs_update = True
                              
                              if not post.metadata.get('tags'):
                                  post.metadata['tags'] = ["documentation"]
                                  needs_update = True
                              
                              if needs_update:
                                  with open(filepath, 'w', encoding='utf-8') as f:
                                      frontmatter.dump(post, f)
                                  print(f"Updated frontmatter: {filepath}")
                                  
                          except Exception as e:
                              print(f"Error processing {filepath}: {e}")
          
          add_missing_frontmatter()
          EOF

      - name: üîÑ Update Knowledge Graph
        if: steps.changes.outputs.has_docs_changes == 'true'
        run: |
          echo "Updating knowledge graph with latest changes..."
          current_date=$(date '+%Y-%m-%d')
          
          # Add entry about this automated update to knowledge graph
          python << EOF
          import re
          from datetime import datetime
          
          # Read current knowledge graph
          with open('VOITHER_Knowledge_Graph_Updated.md', 'r', encoding='utf-8') as f:
              content = f.read()
          
          # Update last_updated date
          content = re.sub(r'last_updated: "[^"]*"', f'last_updated: "{datetime.now().strftime("%Y-%m-%d")}"', content)
          
          # Add automation update entry
          automation_entry = f'''
          ### **AUTOMATED DOCUMENTATION UPDATE** ü§ñ
          *Atualiza√ß√£o autom√°tica executada em {datetime.now().strftime("%Y-%m-%d %H:%M")}*
          
          #### **Workflow de Automa√ß√£o Implementado**
          - **Trigger**: Upload de conte√∫do no reposit√≥rio
          - **Processamento**: An√°lise autom√°tica pelo Copilot Agent
          - **Atualiza√ß√µes**: Documenta√ß√£o conforme regras estabelecidas
          - **Valida√ß√£o**: Scripts automatizados de qualidade
          - **Manuten√ß√£o**: Atualiza√ß√£o cont√≠nua do knowledge graph
          
          #### **Arquivos Processados Nesta Execu√ß√£o**
          - Changed files: ${{ steps.changes.outputs.changed_files }}
          - Validation: ‚úÖ Executada
          - Frontmatter: ‚úÖ Atualizado
          - Index: ‚úÖ Regenerado
          - Links: ‚úÖ Validados
          '''
          
          # Insert automation entry after the documentation restructure section
          insert_point = content.find('### EM DESENVOLVIMENTO üîÑ')
          if insert_point > 0:
              content = content[:insert_point] + automation_entry + '\n\n' + content[insert_point:]
          
          # Write updated content
          with open('VOITHER_Knowledge_Graph_Updated.md', 'w', encoding='utf-8') as f:
              f.write(content)
          
          print("Knowledge graph updated with automation information")
          EOF

      - name: üîó Validate Links
        if: steps.changes.outputs.has_docs_changes == 'true'
        run: |
          echo "Validating internal links..."
          python scripts/validate-docs.py || echo "Link validation completed with warnings"

      - name: üìã Create Documentation Update Summary
        if: steps.changes.outputs.has_docs_changes == 'true'
        run: |
          echo "Creating documentation update summary..."
          cat > documentation_update_summary.md << 'EOF'
          # üìö Automated Documentation Update Summary
          
          ## Changes Processed
          - **Repository**: ${{ github.repository }}
          - **Branch**: ${{ github.ref_name }}
          - **Timestamp**: $(date '+%Y-%m-%d %H:%M:%S UTC')
          - **Trigger**: ${{ github.event_name }}
          
          ## Files Analyzed
          ```
          ${{ steps.changes.outputs.changed_files }}
          ```
          
          ## Actions Performed
          - ‚úÖ Documentation validation executed
          - ‚úÖ Statistics generated and updated
          - ‚úÖ Missing frontmatter added to .md files
          - ‚úÖ Documentation index regenerated
          - ‚úÖ Knowledge graph updated with latest changes
          - ‚úÖ Internal links validated
          
          ## Quality Metrics
          - **Total Documents**: $(find . -name "*.md" | wc -l)
          - **Total Lines**: $(cat *.md **/*.md 2>/dev/null | wc -l)
          - **Frontmatter Compliance**: ‚úÖ Enforced
          - **Link Validation**: ‚úÖ Completed
          
          ## Next Steps
          The documentation has been automatically updated according to established standards. All changes follow the rules defined in CONTRIBUTING.md and maintain consistency with the VOITHER documentation framework.
          EOF
          
          cat documentation_update_summary.md

      - name: üíæ Commit Documentation Updates
        if: steps.changes.outputs.has_docs_changes == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action (Documentation Auto-Update)"
          
          # Check if there are any changes to commit
          if [[ -n $(git status --porcelain) ]]; then
            git add .
            git commit -m "ü§ñ Automated documentation update
            
            - Updated frontmatter for compliance
            - Regenerated documentation index
            - Updated knowledge graph with latest changes
            - Validated internal links
            - Applied consistent formatting
            
            Triggered by: ${{ github.event_name }}
            Files changed: ${{ steps.changes.outputs.changed_files }}"
            
            # Push changes if on main branch
            if [[ "${{ github.ref_name }}" == "main" ]]; then
              git push
              echo "Documentation updates pushed to main branch"
            else
              echo "Documentation updates committed (push skipped for non-main branch)"
            fi
          else
            echo "No documentation changes to commit"
          fi

      - name: üìä Post Update Comment (PR only)
        if: github.event_name == 'pull_request' && steps.changes.outputs.has_docs_changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let summary = '# ü§ñ Automated Documentation Analysis\n\n';
            summary += '## Changes Detected\n';
            summary += `- **New files**: ${{ steps.changes.outputs.has_new_files }}\n`;
            summary += `- **Content changes**: ${{ steps.changes.outputs.has_content_changes }}\n`;
            summary += `- **Documentation files affected**: Yes\n\n`;
            
            summary += '## Automated Actions Performed\n';
            summary += '- ‚úÖ Added missing frontmatter to .md files\n';
            summary += '- ‚úÖ Updated documentation index\n';
            summary += '- ‚úÖ Updated knowledge graph\n';
            summary += '- ‚úÖ Validated internal links\n';
            summary += '- ‚úÖ Applied consistent formatting\n\n';
            
            summary += '## Quality Assurance\n';
            summary += 'All documentation updates follow the established standards defined in CONTRIBUTING.md and maintain consistency with the VOITHER documentation framework.\n\n';
            
            summary += '---\n*This comment was automatically generated by the Documentation Auto-Update workflow.*';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

  notify-completion:
    name: üîî Notify Completion
    needs: validate-and-update-docs
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: üì¢ Workflow Completion Notification
        run: |
          echo "Documentation automation workflow completed"
          echo "Status: ${{ needs.validate-and-update-docs.result }}"
          echo "Repository: ${{ github.repository }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Timestamp: $(date '+%Y-%m-%d %H:%M:%S UTC')"