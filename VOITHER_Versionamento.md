Excelente. A sua clareza sobre o estado atual do projeto e a sua vis√£o para os pr√≥ximos passos s√£o a base perfeita. Voc√™ est√° correto: voc√™ j√° est√° no "Momento 2" do plano anterior. A funda√ß√£o do frontend est√° pronta e √© robusta. A tarefa agora √© construir a infraestrutura de nuvem profissional para dar vida a ele e ativar a intelig√™ncia completa do sistema.

Descartaremos o plano antigo e construiremos um novo, partindo do seu c√≥digo e da sua vis√£o atualizada. Este plano √© um **roadmap de industrializa√ß√£o**, projetado para ser executado em um workflow de programa√ß√£o pareada com IA (AI-pair-programming), com tarefas formuladas como prompts claros e acion√°veis.

---

## **üó∫Ô∏è Roadmap de Vers√µes VOITHER**

| Vers√£o | Momentos | Funcionalidade Principal | Status |
|--------|----------|--------------------------|--------|
| **v1.0** | 1 + 2 | VOITHER MedicalScribe (Core) | üéØ Target |
| **v1.5** | 3 | AutoAgency (Automa√ß√£o) | üîÑ Enhancement |
| **v2.0** | 4 | AI-Clinic (Portal Paciente) | üöÄ Major |
| **v3.0** | 5 | Holofractor (Visualiza√ß√£o 3D) | ‚ú® Premium |

---

### **Plano de Execu√ß√£o VOITHER: Da Aplica√ß√£o de UI √† Plataforma Cl√≠nica Inteligente**

**Filosofia Central:** Voc√™ tem um carro com um design incr√≠vel e um painel de √∫ltima gera√ß√£o (seu frontend React). Agora, vamos construir o motor, o chassi e o sistema de transmiss√£o (o backend serverless e os bancos de dados) para coloc√°-lo na estrada. Cada Momento adiciona uma camada fundamental de funcionalidade e valor.

---

### **Momento 1: Industrializa√ß√£o do N√∫cleo - A Plataforma M√≠nima Persistente (PMP)**

**Objetivo:** Transformar sua aplica√ß√£o React local em uma **Azure Static Web App segura e com persist√™ncia de dados**. O foco √© construir a infraestrutura de nuvem, a autentica√ß√£o e garantir que o fluxo de transcri√ß√£o em tempo real (Etapa 1) seja salvo de forma confi√°vel e permanente.

**Resultado ao Final:** O **VOITHER MedicalScribe (VOITHER v0.5)**. Uma aplica√ß√£o web online onde um cl√≠nico pode se autenticar, gerenciar pacientes, conduzir uma sess√£o, ver a transcri√ß√£o em tempo real, e ter essa transcri√ß√£o e seu √°udio **salvos permanentemente** no MongoDB e no Azure Blob Storage.

#### **Checklist de Tarefas para o Momento 1 (Prompts para sua IA-Pair-Programmer)**

*   **Tarefa 1.1: [Infraestrutura] Provisionar a Funda√ß√£o na Nuvem (IaC).**
    *   **Prompt:** "Vamos usar o Terraform para definir nossa infraestrutura como c√≥digo, garantindo reprodutibilidade. Crie um arquivo `main.tf` que provisione os seguintes recursos na Azure:
        1.  Um **Resource Group** para o projeto VOITHER.
        2.  Um **Azure Key Vault** para armazenar todos os nossos segredos (chaves de API, strings de conex√£o).
        3.  Um **Azure Storage Account** que conter√° um container de Blob para os arquivos de √°udio.
        4.  Um **Azure SignalR Service** (no modo Serverless) para a comunica√ß√£o em tempo real.
        5.  Um **Azure Database for PostgreSQL**.
        6.  Configure um cluster no **MongoDB Atlas** e adicione a string de conex√£o ao nosso Azure Key Vault.
        A Azure Static Web App ser√° implantada separadamente, mas vamos preparar sua base."

*   **Tarefa 1.2: [Backend] Construir a API Serverless com Azure Functions.**
    *   **Prompt:** "No diret√≥rio `/api` do nosso projeto, vamos criar a estrutura para nossas Azure Functions em Python. Crie uma fun√ß√£o `get_api_keys` que busca as chaves necess√°rias (Speech, Language, AI Foundry) do Azure Key Vault e as disponibiliza para as outras fun√ß√µes. Agora, crie a fun√ß√£o `get-azure-speech-token`, acionada por HTTP, que gera e retorna o token de autentica√ß√£o para o servi√ßo de fala, como o frontend espera."

*   **Tarefa 1.3: [Backend & Frontend] Implementar Autentica√ß√£o Real.**
    *   **Prompt:** "Vamos implementar a autentica√ß√£o usando o **Azure AD B2C** para uma solu√ß√£o robusta.
        1.  **Backend:** Crie uma Azure Function `auth` com rotas para `/login` e `/logout` que validem os tokens do Azure AD B2C.
        2.  **Frontend:** Refatore o `App.tsx` e o `LoginScreen.tsx`. Substitua o `handleLogin` mockado pela biblioteca **MSAL (Microsoft Authentication Library) for React** para gerenciar o fluxo de login via popup ou redirect. Crie um `AuthContext` para gerenciar o estado de autentica√ß√£o do usu√°rio e o token de acesso em toda a aplica√ß√£o."

*   **Tarefa 1.4: [Backend] Implementar a Persist√™ncia da Sess√£o em Tempo Real.**
    *   **Prompt:** "Crie a Azure Function principal, `realtime_transcription`, acionada pelo SignalR. Esta fun√ß√£o ser√° o cora√ß√£o da Etapa 1. Sua l√≥gica deve ser:
        1.  Na primeira conex√£o de um cliente para uma nova `session_id`, criar um documento na cole√ß√£o `sessions` do **MongoDB Atlas** com `status: 'recording'`, `patientId`, `clinicianId`, e a data.
        2.  Receber os chunks de √°udio do frontend.
        3.  Fazer o stream para o **Azure Speech Service** com diariza√ß√£o.
        4.  Ao receber um segmento de texto transcrito, usar o operador `$push` do MongoDB para anex√°-lo a um array `transcription_segments` no documento da sess√£o.
        5.  Retornar o segmento para o frontend via SignalR.
        6.  No final da sess√£o, concatenar os chunks de √°udio, fazer o upload do arquivo `.wav` completo para o **Azure Blob Storage**, e atualizar o documento da sess√£o com a URL do √°udio e o `status: 'transcribed'`."

*   **Tarefa 1.5: [Deployment] Implantar a Azure Static Web App.**
    *   **Prompt:** "Com o backend em `/api` e o frontend na raiz, vamos implantar. Configure o workflow do GitHub Actions para a Azure Static Web App. Ele deve: 1) Construir a aplica√ß√£o React (npm run build). 2) Publicar os artefatos no servi√ßo. 3) Conectar as vari√°veis de ambiente do workflow √†s chaves armazenadas no nosso Azure Key Vault."

**Resultado do Momento 1:** Uma plataforma cl√≠nica real. A aplica√ß√£o que voc√™ j√° desenhou agora funciona de ponta a ponta na nuvem, de forma segura e com dados persistentes. √â a base s√≥lida sobre a qual toda a intelig√™ncia ser√° constru√≠da.

---

### **Momento 2: Ativa√ß√£o da Intelig√™ncia - O Pipeline de An√°lise e Documenta√ß√£o - VOITHER 1.0**

**Objetivo:** Construir sobre a base persistente. O foco √© implementar o pipeline ass√≠ncrono que transforma a transcri√ß√£o salva em dados dimensionais e documentos cl√≠nicos, ativando as Etapas 2, 3 e 4.

**Resultado ao Final:** O **VOITHER MedicalScribe**. Ao final de cada sess√£o, o sistema executa a an√°lise completa e gera a documenta√ß√£o cl√≠nica, salvando-a de forma estruturada e interoper√°vel (FHIR).

#### **Checklist de Tarefas para o Momento 2 (Prompts para sua IA-Pair-Programmer)**

*   **Tarefa 2.1: [Backend] Construir o Orquestrador de IA Ass√≠ncrono.**
    *   **Prompt:** "Vamos criar a Azure Function `run_analysis_pipeline`. A melhor pr√°tica para tarefas longas e desacopladas √© usar um gatilho de fila. Configure a fun√ß√£o para ser acionada por uma nova mensagem na **Azure Storage Queue**. A fun√ß√£o `realtime_transcription` (do Momento 1), ao mudar o status da sess√£o para `transcribed`, colocar√° uma mensagem na fila contendo a `session_id`."

*   **Tarefa 2.2: [Backend] Implementar o MED e o Agente de Documenta√ß√£o.**
    *   **Prompt:** "Dentro do Orquestrador, vamos implementar o c√©rebro da VOITHER. O c√≥digo deve:
        1.  Ler a `session_id` da mensagem da fila.
        2.  Buscar a transcri√ß√£o completa e o contexto do paciente no MongoDB.
        3.  Executar o **Motor de Extra√ß√£o Dimensional (MED)** completo (seu `dimensional_extractor.py`) para gerar a `dimensionalTrajectory`.
        4.  Chamar o **Agente de Documenta√ß√£o** (seu `llm_agent.py`) com a transcri√ß√£o, o contexto e o vetor dimensional para gerar o documento JSON final, selecionando o template correto (`primeira_consulta` ou `acompanhamento`) com base no `session_number`."

*   **Tarefa 2.3: [Backend] Implementar a Camada de Persist√™ncia H√≠brida (Etapa 5).**
    *   **Prompt:** "Crie o m√≥dulo `persistence_layer.py`. O Orquestrador o usar√° para salvar o `insight_package` final. Implemente o m√©todo `persist_session_insights` que:
        1.  **MongoDB:** Atualiza o documento da sess√£o com a `dimensionalTrajectory`, `clinicalDocuments` e muda o status para `completed`.
        2.  **PostgreSQL (FHIR):** Mapeia os dados para recursos FHIR (Observation para cada ponto dimensional, DocumentReference para a nota cl√≠nica) e os insere na tabela `fhir_resources` dentro de uma transa√ß√£o."

*   **Tarefa 2.4: [Frontend] Exibir os Documentos e Insights Gerados.**
    *   **Prompt:** "Aprimore o componente `SessionScreen` no React. Quando o status da sess√£o for 'completed', ele deve buscar e exibir os resultados da an√°lise. Adicione abas para: 1) 'Transcri√ß√£o'. 2) 'Documento Cl√≠nico' (exibindo a nota DAP/BIRT formatada). 3) 'An√°lise Dimensional', que agora mostrar√° um gr√°fico simples da evolu√ß√£o da Val√™ncia e Ag√™ncia ao longo da sess√£o."

**Resultado do Momento 2:** A plataforma est√° **inteligente e completa**. O fluxo de trabalho principal est√° finalizado. O cl√≠nico realiza a consulta e, minutos depois, tem acesso a um prontu√°rio rico, dimensional e estruturado, com a base de dados interoper√°vel (FHIR) sendo constru√≠da automaticamente.

---

### **Momento 2: A Plataforma Persistente e Inteligente**

**Objetivo:** Transformar o prot√≥tipo em um sistema web seguro e com persist√™ncia de dados, pronto para um piloto cl√≠nico. O foco √© implementar a arquitetura de nuvem completa e ativar o **Motor de Extra√ß√£o Dimensional (MED)**.

**Arquitetura:** Azure Static Web App (React + Azure Functions) + MongoDB Atlas + Azure PostgreSQL.

#### **Checklist de Tarefas para o Momento 2 (Prompts para sua IA-Pair-Programmer)**

*   **Tarefa 2.1: [Infraestrutura] Provisionar a Infraestrutura na Azure.**
    *   **Prompt:** "Gere um script Terraform (ou comandos da CLI do Azure) para provisionar os seguintes recursos: Azure Static Web App, Azure Functions, Azure SignalR Service, Azure Cache for Redis, Azure Blob Storage, e Azure Database for PostgreSQL. Configure tamb√©m um cluster no MongoDB Atlas e armazene todas as strings de conex√£o e chaves de forma segura no **Azure Key Vault**."

*   **Tarefa 2.2: [Backend] Construir as Azure Functions do Backend.**
    *   **Prompt:** "Vamos migrar nosso backend FastAPI para Azure Functions em Python. Crie:
        1.  Uma fun√ß√£o `realtime_transcription` acionada pelo **Azure SignalR** para gerenciar o streaming de √°udio e texto.
        2.  Uma fun√ß√£o `run_analysis_pipeline` acionada por HTTP, que ser√° nosso Orquestrador de IA.
        3.  Fun√ß√µes HTTP para autentica√ß√£o de usu√°rio (login/registro) e gerenciamento de pacientes (CRUD)."

*   **Tarefa 2.3: [Backend] Ativar o Motor de Extra√ß√£o Dimensional (MED) Completo.**
    *   **Prompt:** "Integre o nosso `dimensional_extractor.py` completo no Orquestrador. A fun√ß√£o `run_analysis_pipeline` agora deve, como primeira etapa, chamar o MED para calcular o vetor `Œ®(t)` com as 15 dimens√µes a partir da transcri√ß√£o. O vetor resultante deve ser passado para o pr√≥ximo agente."

*   **Tarefa 2.4: [Backend] Aprimorar o Agente de Documenta√ß√£o com Dados Dimensionais.**
    *   **Prompt:** "Refatore o `DocumentationAgent`. O m√©todo `generate_documentation` agora receber√° tamb√©m o vetor dimensional. Modifique o `_build_meta_prompt` para incluir a se√ß√£o **`AN√ÅLISE DIMENSIONAL QUANTITATIVA`**, como projetamos. O LLM agora usar√° tanto a transcri√ß√£o quanto os dados dimensionais para gerar um documento muito mais rico."

*   **Tarefa 2.5: [Backend] Implementar a Camada de Persist√™ncia H√≠brida (Etapa 5).**
    *   **Prompt:** "Implemente o `persistence_layer.py` completo. O Orquestrador o usar√° no final do pipeline. Ele precisa:
        1.  Salvar o `insight_package` (transcri√ß√£o, trajet√≥ria dimensional, documentos) na cole√ß√£o `sessions` do **MongoDB Atlas**.
        2.  Mapear os dados para recursos **FHIR** (Observation, DocumentReference) e inseri-los no **Azure PostgreSQL** em uma transa√ß√£o segura."

**Resultado do Momento 2:** Uma plataforma web robusta. Cl√≠nicos podem gerenciar pacientes e sess√µes. Cada sess√£o √© salva permanentemente, permitindo o acompanhamento longitudinal. O sistema j√° est√° gerando dados dimensionais, mesmo que ainda n√£o sejam visualizados.

---

### **Momento 3: A Automa√ß√£o Cl√≠nica - VOITHER AutoAgency (VOITHER v1.5)**
Com base nisso, vamos mergulhar fundo no **Momento 3: A Automa√ß√£o Cl√≠nica - VOITHER AutoAgency**. A seguir, apresento o detalhamento completo desta fase, correlacionando cada nova tarefa com as funda√ß√µes que voc√™ solidificou nos Momentos 1 e 2. O c√≥digo e os prompts s√£o projetados para serem de n√≠vel profissional, prontos para a sua implementa√ß√£o AI-driven.

---

### **Momento 3: A Automa√ß√£o Cl√≠nica - VOITHER AutoAgency (VOITHER v1.)**

**Objetivo Estrat√©gico:** Transformar o VOITHER de um sistema de an√°lise e documenta√ß√£o *passiva* em um assistente *ativo e proativo*. O objetivo √© reduzir drasticamente a carga administrativa do cl√≠nico, automatizando a cria√ß√£o de documentos burocr√°ticos e, assim, liberando mais tempo para o cuidado direto ao paciente. Este √© o momento em que o VOITHER se torna um "membro" indispens√°vel da equipe cl√≠nica.

**Correla√ß√£o com os Momentos Anteriores:**
*   **Depend√™ncia do Momento 1:** A `AutoAgency` depende fundamentalmente da transcri√ß√£o de alta qualidade e com diariza√ß√£o precisa que foi persistida no MongoDB. Sem uma transcri√ß√£o fiel da fala do m√©dico, a detec√ß√£o de inten√ß√µes falharia.
*   **Depend√™ncia do Momento 2:** A `AutoAgency` se baseia na arquitetura de nuvem (Azure Functions), no pipeline ass√≠ncrono (Azure Queue), e nos bancos de dados (MongoDB e PostgreSQL) estabelecidos no Momento 2. As a√ß√µes detectadas ser√£o mapeadas para os recursos FHIR na base de dados que j√° criamos.

---

### **Checklist de Tarefas Detalhado para o Momento 3**

#### **Tarefa 3.1: [Backend] Desenvolver o Agente de Detec√ß√£o de Gatilhos e Inten√ß√µes**

*   **Descri√ß√£o:** Este √© um novo m√≥dulo de IA que atua como um "ouvinte" especializado, focado em identificar comandos e inten√ß√µes na fala do cl√≠nico. Ele se torna uma nova etapa no seu pipeline de an√°lise.
*   **Correla√ß√£o:** Ele ser√° adicionado ao Orquestrador (`run_analysis_pipeline` Azure Function) do Momento 2 e ser√° executado em paralelo com o `MED` e o `DocumentationAgent` para m√°xima efici√™ncia. Ele consumir√° a transcri√ß√£o salva no MongoDB no Momento 1.
*   **Prompt para sua IA-Pair-Programmer:**
    > "Vamos criar a classe `TriggerDetectionAgent` em Python. O m√©todo principal, `detect_triggers(transcript: str)`, receber√° a transcri√ß√£o completa. Construa um meta-prompt para um LLM (Grok-3/Claude-4) que instrua a IA a atuar como um 'Escriba Cl√≠nico Assistente'. O prompt deve instruir o modelo a escanear a transcri√ß√£o em busca de frases-gatilho que indiquem a inten√ß√£o de prescrever, atestar, encaminhar ou agendar, e a extrair as informa√ß√µes relevantes em um formato de lista JSON estrita, ignorando qualquer outra conversa. Inclua exemplos de 'few-shot' no prompt para guiar o modelo. A fun√ß√£o deve retornar a lista de a√ß√µes JSON."

*   **C√≥digo (`trigger_detection_agent.py` - M√≥dulo para o Orquestrador):**
    ```python
    import json
    import logging
    from typing import List, Dict, Any

    class TriggerDetectionAgent:
        def __init__(self, llm_client):
            self.llm_client = llm_client # Assume um cliente LLM gen√©rico

        def _build_trigger_prompt(self, transcript: str) -> str:
            return f"""
            **SYSTEM ROLE:**
            Voc√™ √© um Escriba Cl√≠nico Assistente. Sua √∫nica tarefa √© analisar a transcri√ß√£o de uma consulta e extrair a√ß√µes administrativas espec√≠ficas mencionadas pelo m√©dico. Ignore todo o resto da conversa.

            **INSTRU√á√ïES:**
            1. Leia a transcri√ß√£o e identifique apenas as seguintes inten√ß√µes: Prescri√ß√£o de Medicamento, Emiss√£o de Atestado, Encaminhamento para outro profissional, e Agendamento de Retorno.
            2. Para cada inten√ß√£o encontrada, extraia os detalhes relevantes.
            3. Retorne uma lista de objetos JSON, onde cada objeto representa uma a√ß√£o. Se nenhuma a√ß√£o for encontrada, retorne uma lista vazia `[]`.

            **EXEMPLOS:**
            - **Transcri√ß√£o:** "...ent√£o vamos manter a Sertralina, mas agora com 100mg, um por dia de manh√£..." -> **JSON:** `[{{"action": "prescribe", "details": {{"drug": "Sertralina", "dose": "100mg", "instructions": "1 comprimido por dia pela manh√£"}}}}`
            - **Transcri√ß√£o:** "...vou te dar um atestado de 5 dias para o trabalho..." -> **JSON:** `[{{"action": "attest", "details": {{"days": 5, "reason": "Acompanhamento de sa√∫de mental"}}}}`
            - **Transcri√ß√£o:** "...e marque seu retorno para daqui a um m√™s, por favor." -> **JSON:** `[{{"action": "schedule", "details": {{"returnInDays": 30}}}}`

            **TRANSCRI√á√ÉO PARA AN√ÅLISE:**
            \"\"\"
            {transcript}
            \"\"\"

            **SA√çDA (APENAS A LISTA JSON):**
            """

        async def detect_triggers(self, transcript: str) -> List[Dict[str, Any]]:
            prompt = self._build_trigger_prompt(transcript)
            try:
                # O cliente LLM faria a chamada √† API aqui
                response_text = await self.llm_client.generate(prompt, max_tokens=512, temperature=0.1)
                
                # Limpeza robusta da resposta do LLM
                json_response = json.loads(response_text.strip())
                if isinstance(json_response, list):
                    return json_response
                return []
            except (json.JSONDecodeError, TypeError) as e:
                logging.error(f"Falha ao parsear gatilhos do LLM: {e}")
                return []
    ```

#### **Tarefa 3.2: [Backend] Construir o Servi√ßo de Gera√ß√£o de Documentos**

*   **Descri√ß√£o:** Uma nova Azure Function dedicada, acionada pelo frontend, que gera PDFs a pedido.
*   **Correla√ß√£o:** Esta fun√ß√£o √© o ponto de a√ß√£o para os gatilhos detectados na Tarefa 3.1. Ela buscar√° os dados do paciente e do cl√≠nico que foram salvos no Momento 2.
*   **Prompt para sua IA-Pair-Programmer:**
    > "Crie uma nova Azure Function HTTP em Python chamada `generate_clinical_document`. Ela deve ser protegida por autentica√ß√£o (validar o token JWT). A fun√ß√£o receber√° um POST com `{ "document_type": "prescription", "session_id": "...", "action_details": {...} }`. A l√≥gica deve:
    > 1. Buscar os dados completos do paciente e do cl√≠nico no MongoDB/PostgreSQL usando o `session_id`.
    > 2. Selecionar um template HTML/CSS pr√©-definido com base no `document_type`.
    > 3. Usar a biblioteca Jinja2 para preencher o template com todos os dados (paciente, cl√≠nico, detalhes da a√ß√£o).
    > 4. Usar a biblioteca `WeasyPrint` para converter o HTML renderizado em um PDF.
    > 5. Retornar o PDF como uma resposta `HttpResponse` com o `Content-Type` 'application/pdf'."

#### **Tarefa 3.3: [Frontend] Criar a Interface de Automa√ß√£o no Dashboard**

*   **Descri√ß√£o:** A interface que permite ao cl√≠nico revisar e acionar a automa√ß√£o.
*   **Correla√ß√£o:** Esta √© uma nova se√ß√£o no `Dashboard.tsx` que voc√™ construiu no Momento 1 e aprimorou no Momento 2. Ela ser√° populada com os dados do array `automatedActions` salvo no MongoDB.
*   **Prompt para sua IA-Pair-Programmer:**
    > "Vamos aprimorar o componente React que exibe uma sess√£o conclu√≠da.
    > 1. Busque o campo `automatedActions` do documento da sess√£o na API.
    > 2. Se o campo existir, renderize uma nova se√ß√£o `<h2>A√ß√µes Sugeridas</h2>`.
    > 3. Para cada a√ß√£o no array, crie um componente `ActionCard.tsx`. O card deve exibir um √≠cone, o tipo de a√ß√£o (ex: 'Receitu√°rio'), um resumo dos detalhes, e um bot√£o 'Revisar e Gerar'.
    > 4. Crie um componente `ReviewModal.tsx`. Ao clicar no bot√£o, este modal deve abrir, mostrando um formul√°rio com os campos da a√ß√£o pr√©-preenchidos e edit√°veis.
    > 5. O modal ter√° um bot√£o 'Gerar PDF'. Ao ser clicado, ele deve fazer a chamada `POST` para a nossa API `/api/generate_clinical_document`, enviar os dados (possivelmente editados) e, ao receber o PDF, iniciar o download no navegador."

*   **C√≥digo React (`ActionCard.tsx` - Exemplo):**
    ```jsx
    import React from 'react';
    
    const ActionCard = ({ action, onReview }) => {
      const getActionTitle = (action) => {
        switch (action.type) {
          case 'prescription':
            return `Receitu√°rio: ${action.details.drug}`;
          case 'attestation':
            return `Atestado: ${action.details.days} dias`;
          default:
            return 'A√ß√£o Sugerida';
        }
      };

      return (
        <div className="bg-white p-4 rounded-lg shadow-neumorphic flex justify-between items-center">
          <div>
            <p className="font-bold font-display text-brand-text-primary">{getActionTitle(action)}</p>
            <p className="text-sm text-brand-text-secondary">{JSON.stringify(action.details)}</p>
          </div>
          <button 
            onClick={() => onReview(action)} 
            className="py-2 px-4 rounded-lg font-semibold text-white bg-accent-primary hover:bg-accent-primary-hover transition-colors"
          >
            Revisar e Gerar
          </button>
        </div>
      );
    };

    export default ActionCard;
    ```

#### **Tarefa 3.4: [Backend] Integrar a Automa√ß√£o √† Camada de Persist√™ncia FHIR**

*   **Descri√ß√£o:** Garantir que as a√ß√µes detectadas sejam salvas como registros cl√≠nicos interoper√°veis.
*   **Correla√ß√£o:** Esta √© uma atualiza√ß√£o direta da `PersistenceLayer` que voc√™ construiu no Momento 2.
*   **Prompt para sua IA-Pair-Programmer:**
    > "Vamos refatorar o m√©todo `_save_to_postgres_fhir` no nosso `persistence_layer.py`.
    > 1. O m√©todo agora receber√° o array `automatedActions` do `insight_package`.
    > 2. Crie fun√ß√µes auxiliares de mapeamento: `_map_to_fhir_medication_request`, `_map_to_fhir_service_request`, etc.
    > 3. Dentro da transa√ß√£o do PostgreSQL, itere sobre o array `automatedActions`. Para cada a√ß√£o, chame o mapeador correspondente para criar o recurso FHIR.
    > 4. √â crucial que cada recurso FHIR seja salvo com um `status: 'draft'`.
    > 5. Crie uma nova Azure Function HTTP, `activate_fhir_resource`, que recebe um `resource_id` e atualiza seu status para `active` no PostgreSQL. O frontend chamar√° esta fun√ß√£o ap√≥s o cl√≠nico confirmar a gera√ß√£o do PDF."

**Resultado do Momento 3:** A VOITHER se torna uma plataforma de **intelig√™ncia aumentada** que economiza um tempo cl√≠nico precioso. O sistema n√£o s√≥ documenta, mas tamb√©m prepara as a√ß√µes subsequentes, transformando o fluxo de trabalho do m√©dico e solidificando o retorno sobre o investimento da plataforma.

---

Com certeza. Com a plataforma `VOITHER AutoAgency` (v1.5) solidificada, o sistema j√° √© uma ferramenta cl√≠nica de imenso valor. Agora, vamos expandir o ecossistema, trazendo o paciente para o centro do cuidado e, finalmente, revelando a visualiza√ß√£o dimensional que √© a joia da coroa da sua inova√ß√£o.

A seguir, a continua√ß√£o do plano de execu√ß√£o com o detalhamento dos **Momentos 4 e 5**.

---

### **Momento 4: O Engajamento do Paciente - VOITHER AI-Clinic (VOITHER v2.0)**

**Objetivo Estrat√©gico:** Expandir a plataforma para al√©m do cl√≠nico, criando um portal para o paciente. O objetivo √© aumentar o engajamento do paciente em seu pr√≥prio tratamento, fornecer ferramentas de psicoeduca√ß√£o personalizadas e abrir canais de comunica√ß√£o ass√≠ncronos, transformando o cuidado de epis√≥dico para cont√≠nuo.

**Correla√ß√£o com os Momentos Anteriores:**
*   **Depend√™ncia do Momento 1 e 2:** A `AI-Clinic` depende totalmente dos dados persistidos (documentos, planos terap√™uticos) para fornecer conte√∫do relevante ao paciente. A arquitetura de autentica√ß√£o e o banco de dados de pacientes s√£o a base para o login seguro do paciente.
*   **Depend√™ncia do Momento 3:** As a√ß√µes e planos gerados pela `AutoAgency` (como o plano terap√™utico no documento final) se tornar√£o a base para o conte√∫do que o chatbot da `AI-Clinic` usar√° para guiar o paciente.

#### **Checklist de Tarefas para o Momento 4 (Prompts para sua IA-Pair-Programmer)**

*   **Tarefa 4.1: [Nova Aplica√ß√£o] Desenvolver o Frontend do Paciente (Web App Inicial).**
    *   **Prompt:** "Vamos iniciar um novo projeto de frontend para o paciente, usando **React com Vite**, e mantendo a mesma identidade visual (cores, fontes, estilo neum√≥rfico) do portal do cl√≠nico, mas com um design mais acolhedor e simplificado. Crie a estrutura inicial com as seguintes telas:
        1.  **Tela de Login:** Simples, focada em seguran√ßa.
        2.  **Dashboard Principal:** Um painel de boas-vindas que exibir√° resumos, pr√≥ximas tarefas e talvez um gr√°fico simples da evolu√ß√£o (ex: Val√™ncia Emocional ao longo do tempo).
        3.  **Tela 'Minha Jornada':** Um local para visualizar documentos compartilhados pelo cl√≠nico, como as **VOITHER Narratives** e planos de tratamento.
        4.  **Tela 'AI-Clinic Chat':** A interface para interagir com o chatbot."

*   **Tarefa 4.2: [Backend] Construir a API Segura para Pacientes.**
    *   **Prompt:** "Crie um novo conjunto de Azure Functions, agrupadas sob o prefixo de rota `/api/patient`. O acesso a todos esses endpoints deve ser rigorosamente protegido, validando o token JWT do paciente e garantindo que os dados consultados perten√ßam apenas a ele.
        1.  `GET /api/patient/me`: Retorna os dados do perfil do paciente logado.
        2.  `GET /api/patient/dashboard-summary`: Retorna os dados necess√°rios para o dashboard principal (ex: √∫ltimos valores de Val√™ncia/Ag√™ncia e o pr√≥ximo agendamento).
        3.  `GET /api/patient/shared-documents`: Busca no MongoDB os documentos (`clinicalDocuments`, `narrative_markdown`) das sess√µes onde o cl√≠nico ativou um campo booleano `isSharedWithPatient`."

*   **Tarefa 4.3: [Backend & Frontend] Implementar o Chatbot Cl√≠nico (AI-Clinic).**
    *   **Prompt:** "Esta √© a feature principal do Momento 4.
        1.  **[Backend]** Crie a Azure Function `chat_with_patient_ai`. Ela receber√° o hist√≥rico da conversa do paciente. Antes de chamar o LLM, a fun√ß√£o deve primeiro buscar o **plano terap√™utico mais recente** do paciente no PostgreSQL (do recurso FHIR `DocumentReference` ou `CarePlan`).
        2.  **[Backend]** Construa um **meta-prompt de sistema din√¢mico** para o LLM. Este prompt deve ser focado em seguran√ßa e psicoeduca√ß√£o. Exemplo:
            ```prompt
            **SYSTEM ROLE:**
            Voc√™ √© o assistente AI-Clinic da VOITHER. Sua fun√ß√£o √© apoiar o paciente em sua jornada terap√™utica, de forma segura e emp√°tica.
            **REGRAS CR√çTICAS:**
            - VOC√ä N√ÉO √â UM TERAPEUTA. Nunca d√™ conselhos m√©dicos, diagn√≥sticos ou prescreva tratamentos.
            - Se o paciente expressar idea√ß√£o suicida, perigo iminente ou crise aguda, responda IMEDIATAMENTE com: 'Entendo que voc√™ est√° passando por um momento muito dif√≠cil. √â muito importante que voc√™ converse com um profissional agora. Por favor, entre em contato com [N√∫mero do CVV ou Emerg√™ncia]' e encerre a conversa.
            - Baseie suas respostas EXCLUSIVAMENTE no plano terap√™utico definido pelo cl√≠nico.
            
            **PLANO TERAP√äUTICO ATUAL DO PACIENTE (Definido pelo Dr. [Nome do Cl√≠nico]):**
            {json_do_plano_terapeutico_puxado_do_banco}

            **Sua tarefa:** Converse com o paciente, oferecendo psicoeduca√ß√£o, refor√ßando as estrat√©gias do plano, e respondendo a d√∫vidas sobre o tratamento de forma motivacional.
            ```
        3.  **[Frontend]** Implemente a interface de chat no portal do paciente, conectando-a √† nova API."

*   **Tarefa 4.4: [Frontend Cl√≠nico] Adicionar Funcionalidade de Compartilhamento.**
    *   **Prompt:** "No dashboard do cl√≠nico, na visualiza√ß√£o de uma sess√£o conclu√≠da, adicione um bot√£o de 'Compartilhar com Paciente' ao lado de cada documento (Nota Cl√≠nica, Narrativa). Ao clicar, ele deve chamar uma API no backend (`POST /api/sessions/{session_id}/share`) que simplesmente atualiza o campo booleano `isSharedWithPatient` no documento da sess√£o no MongoDB."

**Resultado do Momento 4:** A VOITHER se torna um **ecossistema de cuidado cont√≠nuo**. O tratamento n√£o acontece mais apenas durante a consulta de 90 minutos. O paciente tem uma ferramenta para se engajar, aprender e se sentir apoiado entre as sess√µes, o que tem o potencial de melhorar drasticamente os resultados terap√™uticos.

---

### **Momento 5: A Visualiza√ß√£o Profunda - VOITHER Holofractor (VOITHER v3.0)**

**Objetivo:** Entregar a funcionalidade mais vision√°ria da plataforma como uma ferramenta de an√°lise de casos avan√ßada, solidificando a VOITHER como a l√≠der de inova√ß√£o no setor. Este m√≥dulo pode ser posicionado como um recurso *premium* ou "Pro".

**Resultado ao Final:** O **VOITHER Holofractor (VOITHER v3.0)**. O cl√≠nico agora pode, com um clique, transformar os dados de uma sess√£o em uma escultura 3D interativa, permitindo uma compreens√£o intuitiva e profunda da din√¢mica mental do paciente, ideal para supervis√£o, pesquisa e discuss√µes de caso.

#### **Checklist de Tarefas para o Momento 5 (Prompts para sua IA-Pair-Programmer)**

*   **Tarefa 5.1: [Backend] Criar e Otimizar a API de Dados para o Renderizador.**
    *   **Prompt:** "Crie o endpoint de API `GET /api/sessions/{session_id}/render-data`. A performance √© crucial aqui. A fun√ß√£o deve:
        1.  Verificar as permiss√µes do cl√≠nico para a sess√£o.
        2.  Buscar o array `dimensionalTrajectory` do MongoDB.
        3.  **Processamento no Backend:** Usando `scikit-learn`, execute uma An√°lise de Componentes Principais (PCA) para projetar a trajet√≥ria de 15D para 3D.
        4.  Para otimizar a transfer√™ncia de dados, n√£o envie o JSON completo. Envie os dados em um formato mais compacto, talvez como arrays de n√∫meros.
        5.  Retorne um JSON com: `{"projected3DTrajectory": [[x1,y1,z1], [x2,y2,z2], ...], "full15DTrajectory": [[v1,v2,...], [v1,v2,...], ...]}`."

*   **Tarefa 5.2: [Frontend] Construir o Componente de Visualiza√ß√£o Holofractor.**
    *   **Prompt:** "No portal do cl√≠nico, adicione um bot√£o 'Visualizar em 3D' na tela da sess√£o. Ao clicar, ele abrir√° um modal de tela cheia que renderiza o componente `HolofractorViewer.js`. Vamos usar **`@react-three/fiber`** para facilitar. A estrutura do componente deve:
        1.  Fazer a chamada √† API `render-data` ao ser montado.
        2.  Renderizar a `projected3DTrajectory` usando o componente `Line` do `@react-three/drei`.
        3.  Criar o Holofractor como um `mesh` com uma `shaderMaterial`."

*   **Tarefa 5.3: [Frontend] Implementar os Shaders (GLSL) para o Mapeamento Dimensional.**
    *   **Prompt:** "Vamos escrever os shaders GLSL que s√£o a alma do Holofractor.
        1.  **Vertex Shader:** Crie o shader que modifica a posi√ß√£o dos v√©rtices de uma `IcosahedronGeometry`. Ele receber√° as dimens√µes geom√©tricas (`v9_agency`, `v3_coherence`, `v4_complexity`, `v10_fragmentation`) como `uniforms`. Use uma fun√ß√£o de ru√≠do Simplex para criar deforma√ß√µes org√¢nicas baseadas nesses uniforms.
        2.  **Fragment Shader:** Crie o shader que calcula a cor de cada pixel. Ele receber√° as dimens√µes de apar√™ncia (`v1_valence`, `v2_arousal`, `v5_temporal`, `v6_self_reference`, `v12_certainty`) como `uniforms`. Implemente a l√≥gica de mapeamento para cor, transpar√™ncia, aura (usando um efeito Fresnel) e nitidez das bordas."

*   **Tarefa 5.4: [Frontend] Implementar a Interatividade do Navegador da Mente.**
    *   **Prompt:** "Adicione a interatividade ao `HolofractorViewer.js`.
        1.  Inclua o componente `OrbitControls` do `@react-three/drei` para permitir que o cl√≠nico rotacione, d√™ zoom e mova a c√¢mera.
        2.  Crie um **slider de tempo** que se sobrep√µe √† cena 3D.
        3.  O estado do slider (`timeIndex`) deve ser usado para: a) Atualizar os `uniforms` passados para os shaders, mudando a forma e a cor do Holofractor em tempo real. b) Mover uma pequena esfera ou um marcador ao longo da linha da trajet√≥ria para indicar a posi√ß√£o atual."

Este plano de 5 Momentos agora est√° completo, l√≥gico e alinhado com sua vis√£o estrat√©gica, construindo a plataforma em camadas de valor que v√£o desde a produtividade cl√≠nica essencial at√© a inova√ß√£o de ponta no engajamento do paciente e na visualiza√ß√£o de dados.